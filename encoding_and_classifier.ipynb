{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36b6b545",
   "metadata": {},
   "source": [
    "# Task 2 Encoding and Classifier\n",
    "\n",
    "\n",
    "Encoding the following files in a quantum circuit mock_train_set.csv and mock_test_set.csv in at least two different ways (these could be basis, angle,  amplitude, kernel or random encoding).\n",
    "Design a variational quantum circuit for each of the encodings, uses the column 4  as the target,  this is a binary class 0 and 1.\n",
    "You must  use the data  from column0 to column3 for your proposed classifier. \n",
    "Consider the ansatz you are going to design as a layer and find out how many layers are necessary to reach the best performance.\n",
    "\n",
    "Analyze and discuss the results.\n",
    "\n",
    "Feel free to use existing frameworks (e.g. PennyLane, Qiskit) for creating and training the circuits.\n",
    "This PennyLane demo can be useful: Training a quantum circuit with Pytorch, \n",
    "This Quantum Tensorflow tutorial can be useful: Training a quantum circuit with Tensorflow.\n",
    "\n",
    "For the variational circuit, you can try any circuit you want. You can start from one with a layer of RX, RZ and CNOTs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720c374b",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26768f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import pennylane.optimize as optimize\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc9fa46",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affbeaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the training dataset: (300, 4)\n",
      "The size of the test dataset: (120, 4)\n",
      "The size of the training label: (300,)\n",
      "The size of the test label: (120,)\n"
     ]
    }
   ],
   "source": [
    "def read_file(filename):\n",
    "    \"\"\"Read csv file\n",
    "    Args:\n",
    "      - filename (string): the file name\n",
    "    Returns:\n",
    "      - rows (list): a list of rows in the file\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        # creating a csv reader object\n",
    "        csvreader = csv.reader(csvfile)\n",
    "\n",
    "        # extracting each data row one by one\n",
    "        for row in csvreader:\n",
    "            rows.append(row)\n",
    "    return rows\n",
    "\n",
    "train_dataset = np.array(read_file(\"mock_train_set.csv\"), dtype=float)\n",
    "test_dataset = np.array(read_file(\"mock_test_set.csv\"), dtype=float)\n",
    "\n",
    "train_X, train_Y = train_dataset[1:, 0:4], train_dataset[1:, 4].astype('int')\n",
    "test_X, test_Y = test_dataset[1:, 0:4], test_dataset[1:, 4].astype('int')\n",
    "\n",
    "# shift label from {0, 1} to {-1, 1}\n",
    "train_Y = train_Y * 2 - np.ones(len(train_Y))\n",
    "test_Y = test_Y * 2 - np.ones(len(test_Y))\n",
    "\n",
    "print(\"The size of the training dataset:\", train_X.shape)\n",
    "print(\"The size of the test dataset:\", test_X.shape)\n",
    "print(\"The size of the training label:\", train_Y.shape)\n",
    "print(\"The size of the test label:\", test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7449e809",
   "metadata": {},
   "source": [
    "As can be seen, the data size is not large, with 300 training data and 120 test data. In the later training, the training data will be further split into training data (75%) and validation data (25%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e03d718",
   "metadata": {},
   "source": [
    "## Data Min-Max Normalization (Each Column)\n",
    "\n",
    "For the data attributes, the value ranges in each column is quite different. To aid the convergence of the training, the min-max normalization is applied for each column of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f05cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data for each column 1, 2, 3, 4\n",
    "def find_min_and_max(arr1, arr2):\n",
    "    \"\"\"Find max and min values for each column in datasets\n",
    "    Args:\n",
    "      - arr1, arr2: the datasets\n",
    "    Returns:\n",
    "      - arr_max, arr_min: arrays with max and min elements in each column, respectively\n",
    "    \"\"\"\n",
    "    arr1_max = np.max(arr1, axis=0)\n",
    "    arr2_max = np.max(arr2, axis=0)\n",
    "    arr_max = np.maximum(arr1_max, arr2_max)\n",
    "    \n",
    "    arr1_min = np.min(arr1, axis=0)\n",
    "    arr2_min = np.min(arr2, axis=0)\n",
    "    arr_min = np.minimum(arr1_min, arr2_min)\n",
    "    \n",
    "    return arr_max, arr_min   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d3d45aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max for each column: [4.99561e+03 1.00000e+06 1.00000e+06 9.00000e+01]\n",
      "The min for each column: [31.71  1.    1.    1.  ]\n"
     ]
    }
   ],
   "source": [
    "X_max, X_min = find_min_and_max(train_X, test_X)\n",
    "print(\"The max for each column:\", X_max)\n",
    "print(\"The min for each column:\", X_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd467e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max normalization \n",
    "for i in range(train_X.shape[1]):\n",
    "    train_X[:, i] = (train_X[:, i] - X_min[i]) / (X_max[i] - X_min[i])\n",
    "    test_X[:, i] = (test_X[:, i] - X_min[i]) / (X_max[i] - X_min[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cb78140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First training X sample (min-max normalization):  [5.55520861e-01 9.99000999e-04 9.00000900e-06 2.13483146e-01]\n",
      "First test X sample (min-max normalization):  [0.59566873 0.00999901 0.00999901 0.83146067]\n"
     ]
    }
   ],
   "source": [
    "print(\"First training X sample (min-max normalization): \", train_X[0])\n",
    "print(\"First test X sample (min-max normalization): \", test_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0d9c91",
   "metadata": {},
   "source": [
    "## Normalize to 1.0 (Each Row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0dfbfb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First training X sample (normalized): [9.33444874e-01 1.67862708e-03 1.51227665e-05 3.58716949e-01]\n",
      "First test X sample (normalized): [0.58232672 0.00977505 0.00977505 0.81283731]\n"
     ]
    }
   ],
   "source": [
    "# normazlie each input\n",
    "normalization_train, normalization_test = np.sqrt(np.sum(train_X ** 2, -1)), np.sqrt(np.sum(test_X ** 2, -1))\n",
    "train_X_norm, test_X_norm = (train_X.T / normalization_train).T, (test_X.T / normalization_test).T\n",
    "print(\"First training X sample (normalized):\", train_X_norm[0])\n",
    "print(\"First test X sample (normalized):\", test_X_norm[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa423930",
   "metadata": {},
   "source": [
    "# Quantum Classifier \n",
    "In this section, two state embedding methods are explored, they are amplitude embedding and angle embedding. Because the feature size is 4, for amplitude embedding, we only need 2 qubits, for angle embedding, we need 4 qubits.\n",
    "## 1. Classifier based on Amplitude Embedding\n",
    "### Quantum Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b900df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    \"\"\"Find square loss between labels and predictions\n",
    "    Args:\n",
    "      - labels: the sample labels\n",
    "      - predictions: the predicted labels\n",
    "    Returns:\n",
    "      - loss: square loss \n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "    \"\"\"Find prediction accuracy\n",
    "    Args:\n",
    "      - labels: the sample labels\n",
    "      - predictions: the predicted labels\n",
    "    Returns:\n",
    "      - accuracy: percentage of right prediction\n",
    "    \"\"\"\n",
    "    accuracy = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            accuracy = accuracy + 1\n",
    "    accuracy = accuracy / len(labels)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b93db3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_amplitude_embedding(W):    \n",
    "    qml.Rot(W[0, 0], W[0, 1], W[0, 2], wires=0)\n",
    "    qml.Rot(W[1, 0], W[1, 1], W[1, 2], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "\n",
    "dev_amplitude_embedding = qml.device(\"default.qubit\", wires=2)\n",
    "@qml.qnode(dev_amplitude_embedding)\n",
    "def circuit_amplitude_embedding(weights, feature):\n",
    "    \"\"\"A quantum circuit used as classifier\n",
    "    Args:\n",
    "      - weights: parameters for layers in the circuit\n",
    "      - feature: sample data\n",
    "    Returns:\n",
    "      - expectation value: expectation value of Pauli z operator\n",
    "    \"\"\"\n",
    "    qml.AmplitudeEmbedding(feature, wires=[0, 1], normalize=True)\n",
    "\n",
    "    for W in weights:\n",
    "        layer_amplitude_embedding(W)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "def variational_classifier_amplitude_embedding(weights, bias, feature):\n",
    "    return circuit_amplitude_embedding(weights, feature) + bias\n",
    "\n",
    "def cost_amplitude_embedding(weights, bias, features, labels):\n",
    "    predictions = [variational_classifier_amplitude_embedding(weights, bias, f) for f in features]\n",
    "    return square_loss(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a995e16",
   "metadata": {},
   "source": [
    "### Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "007a7d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition training datasets to training and validation \n",
    "np.random.seed(0)\n",
    "num_data = len(train_Y)\n",
    "num_train = int(0.75 * num_data) # 75% dataset is used for training\n",
    "index = np.random.permutation(range(num_data))\n",
    "feats_train = train_X_norm[index[:num_train]]\n",
    "label_train = train_Y[index[:num_train]]\n",
    "feats_val = train_X_norm[index[num_train:]]\n",
    "label_val = train_Y[index[num_train:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f76a51b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence for number of layers is equal to : 1\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12345\\Anaconda3\\envs\\hackq\\lib\\site-packages\\autograd\\numpy\\numpy_wrapper.py:156: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return A.astype(dtype, order, casting, subok, copy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Cost: 1.2496464 | Acc train: 0.5600000 | Acc validation: 0.5600000 \n",
      "Iter:    11 | Cost: 1.2165535 | Acc train: 0.5600000 | Acc validation: 0.5600000 \n",
      "Iter:    21 | Cost: 1.2037583 | Acc train: 0.5955556 | Acc validation: 0.5600000 \n",
      "Iter:    31 | Cost: 1.2350238 | Acc train: 0.5866667 | Acc validation: 0.5466667 \n",
      "Iter:    41 | Cost: 1.0280630 | Acc train: 0.6222222 | Acc validation: 0.6000000 \n",
      "Iter:    51 | Cost: 0.8945497 | Acc train: 0.6755556 | Acc validation: 0.6400000 \n",
      "Test accuracy: 0.8583333333333333\n",
      "Convergence for number of layers is equal to : 3\n",
      "----------------------------------------------------------------------\n",
      "Iter:     1 | Cost: 1.2523830 | Acc train: 0.5600000 | Acc validation: 0.5600000 \n",
      "Iter:    11 | Cost: 1.2246969 | Acc train: 0.5644444 | Acc validation: 0.5600000 \n",
      "Iter:    21 | Cost: 1.1035576 | Acc train: 0.6133333 | Acc validation: 0.6133333 \n",
      "Iter:    31 | Cost: 0.9144311 | Acc train: 0.6711111 | Acc validation: 0.6533333 \n",
      "Iter:    41 | Cost: 0.8051973 | Acc train: 0.7111111 | Acc validation: 0.7866667 \n",
      "Iter:    51 | Cost: 0.8111001 | Acc train: 0.6933333 | Acc validation: 0.7866667 \n",
      "Test accuracy: 0.8416666666666667\n",
      "Convergence for number of layers is equal to : 6\n",
      "----------------------------------------------------------------------\n",
      "Iter:     1 | Cost: 1.2504605 | Acc train: 0.5555556 | Acc validation: 0.5600000 \n",
      "Iter:    11 | Cost: 1.1232167 | Acc train: 0.5955556 | Acc validation: 0.5866667 \n",
      "Iter:    21 | Cost: 0.9703915 | Acc train: 0.6177778 | Acc validation: 0.6133333 \n",
      "Iter:    31 | Cost: 0.8705543 | Acc train: 0.7111111 | Acc validation: 0.8000000 \n",
      "Iter:    41 | Cost: 0.7968246 | Acc train: 0.7111111 | Acc validation: 0.7866667 \n",
      "Iter:    51 | Cost: 0.8123826 | Acc train: 0.7022222 | Acc validation: 0.7733333 \n",
      "Test accuracy: 0.8583333333333333\n",
      "Convergence for number of layers is equal to : 8\n",
      "----------------------------------------------------------------------\n",
      "Iter:     1 | Cost: 1.2333031 | Acc train: 0.5511111 | Acc validation: 0.5600000 \n",
      "Iter:    11 | Cost: 1.1744057 | Acc train: 0.5911111 | Acc validation: 0.5600000 \n",
      "Iter:    21 | Cost: 1.0329149 | Acc train: 0.5911111 | Acc validation: 0.5466667 \n",
      "Iter:    31 | Cost: 1.0246228 | Acc train: 0.6400000 | Acc validation: 0.6266667 \n",
      "Iter:    41 | Cost: 0.9900618 | Acc train: 0.6533333 | Acc validation: 0.6400000 \n",
      "Iter:    51 | Cost: 0.8238433 | Acc train: 0.6711111 | Acc validation: 0.7733333 \n",
      "Test accuracy: 0.825\n",
      "Convergence for number of layers is equal to : 10\n",
      "----------------------------------------------------------------------\n",
      "Iter:     1 | Cost: 1.2485481 | Acc train: 0.5600000 | Acc validation: 0.5600000 \n",
      "Iter:    11 | Cost: 0.9567789 | Acc train: 0.6355556 | Acc validation: 0.6000000 \n",
      "Iter:    21 | Cost: 0.9013869 | Acc train: 0.6666667 | Acc validation: 0.6933333 \n",
      "Iter:    31 | Cost: 0.8338361 | Acc train: 0.6755556 | Acc validation: 0.6533333 \n",
      "Iter:    41 | Cost: 0.8149636 | Acc train: 0.7022222 | Acc validation: 0.6400000 \n",
      "Iter:    51 | Cost: 0.8679987 | Acc train: 0.6533333 | Acc validation: 0.6400000 \n",
      "Test accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "num_qubits = 2 # 2 qubits are needed for quantum circuit based on amplitude embedding\n",
    "num_layers = [1, 3, 6, 8, 10]\n",
    "accuracy_amplitude_embedding = []\n",
    "\n",
    "for i in range(len(num_layers)):\n",
    "    opt = optimize.NesterovMomentumOptimizer(0.01)\n",
    "    print(\"Convergence for number of layers is equal to : {}\".format(num_layers[i]))\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    # train the variational classifier      \n",
    "    weights = 0.01 * np.random.randn(num_layers[i], num_qubits, 3, requires_grad=True)\n",
    "    bias =  np.array(0.0, requires_grad=True)\n",
    "    for it in range(60):\n",
    "        # Update the weights by one optimizer step\n",
    "        batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "        feats_train_batch = feats_train[batch_index]\n",
    "        label_train_batch = label_train[batch_index]\n",
    "        weights, bias, _, _ = opt.step(cost_amplitude_embedding, weights, bias, feats_train_batch, label_train_batch)\n",
    "\n",
    "        # Compute predictions on train and validation set\n",
    "        predictions_train = [np.sign(variational_classifier_amplitude_embedding(weights, bias, f)) for f in feats_train]\n",
    "        predictions_val = [np.sign(variational_classifier_amplitude_embedding(weights, bias, f)) for f in feats_val]\n",
    "\n",
    "        # Compute accuracy on train and validation set\n",
    "        acc_train = accuracy(label_train, predictions_train)\n",
    "        acc_val = accuracy(label_val, predictions_val)\n",
    "        \n",
    "        if it%10 == 0:\n",
    "            print(\n",
    "                \"Iter: {:5d} | Cost: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f} \"\n",
    "                \"\".format(it + 1, cost_amplitude_embedding(weights, bias, train_X_norm, train_Y), acc_train, acc_val)\n",
    "            )\n",
    "    # check test accuracy\n",
    "    predictions_test = [np.sign(variational_classifier_amplitude_embedding(weights, bias, f)) for f in test_X_norm]\n",
    "    acc_test = accuracy(test_Y, predictions_test)\n",
    "    print(\"Test accuracy:\", acc_test)\n",
    "    accuracy_amplitude_embedding.append(acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef23575d",
   "metadata": {},
   "source": [
    "## 2. Classifier based on Angle Embedding\n",
    "### Quantum Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d09d7ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_angle_embedding(W):\n",
    "    qml.Rot(W[0, 0], W[0, 1], W[0, 2], wires=0)\n",
    "    qml.Rot(W[1, 0], W[1, 1], W[1, 2], wires=1)\n",
    "    qml.Rot(W[2, 0], W[2, 1], W[2, 2], wires=2)\n",
    "    qml.Rot(W[3, 0], W[3, 1], W[3, 2], wires=3)\n",
    "\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "    qml.CNOT(wires=[2, 3])\n",
    "    qml.CNOT(wires=[3, 0]) \n",
    "    \n",
    "dev_angle_embedding = qml.device(\"default.qubit\", wires=4)\n",
    "@qml.qnode(dev_angle_embedding)\n",
    "def circuit_angle_embedding(weights, angles):\n",
    "    \"\"\"A quantum circuit used as classifier\n",
    "    Args:\n",
    "      - weights: parameters for layers in the circuit\n",
    "      - feature: sample data\n",
    "    Returns:\n",
    "      - expectation value: expectation value of Pauli z operator\n",
    "    \"\"\"\n",
    "    qml.AngleEmbedding(angles, wires=range(4), rotation='Z')\n",
    "\n",
    "    for W in weights:\n",
    "        layer_angle_embedding(W)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "def variational_classifier_angle_embedding(weights, bias, angles):\n",
    "    return circuit_angle_embedding(weights, angles) + bias\n",
    "\n",
    "def cost_angle_embedding(weights, bias, features, labels):\n",
    "    predictions = [variational_classifier_angle_embedding(weights, bias, f) for f in features]\n",
    "    return square_loss(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd87cf",
   "metadata": {},
   "source": [
    "### Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d353c477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence for number of layers is equal to : 1\n",
      "----------------------------------------------------------------------\n",
      "Iter:     1 | Cost: 2.0434767 | Acc train: 0.4888889 | Acc validation: 0.4400000 \n",
      "Iter:    11 | Cost: 1.0767405 | Acc train: 0.4888889 | Acc validation: 0.4400000 \n",
      "Iter:    21 | Cost: 1.0164683 | Acc train: 0.5111111 | Acc validation: 0.5600000 \n",
      "Iter:    31 | Cost: 0.9984465 | Acc train: 0.5111111 | Acc validation: 0.5600000 \n",
      "Iter:    41 | Cost: 1.0059378 | Acc train: 0.4888889 | Acc validation: 0.4400000 \n",
      "Iter:    51 | Cost: 1.0011451 | Acc train: 0.4888889 | Acc validation: 0.4400000 \n",
      "Test accuracy: 0.5166666666666667\n",
      "Convergence for number of layers is equal to : 3\n",
      "----------------------------------------------------------------------\n",
      "Iter:     1 | Cost: 2.0593690 | Acc train: 0.4888889 | Acc validation: 0.4400000 \n",
      "Iter:    11 | Cost: 1.1890292 | Acc train: 0.4888889 | Acc validation: 0.4400000 \n",
      "Iter:    21 | Cost: 1.0129898 | Acc train: 0.5111111 | Acc validation: 0.5600000 \n",
      "Iter:    31 | Cost: 1.0098052 | Acc train: 0.5111111 | Acc validation: 0.5600000 \n",
      "Iter:    41 | Cost: 0.9982166 | Acc train: 0.5111111 | Acc validation: 0.5600000 \n",
      "Iter:    51 | Cost: 1.0164102 | Acc train: 0.4888889 | Acc validation: 0.4400000 \n",
      "Test accuracy: 0.48333333333333334\n",
      "Convergence for number of layers is equal to : 6\n",
      "----------------------------------------------------------------------\n",
      "Iter:     1 | Cost: 2.0570639 | Acc train: 0.4888889 | Acc validation: 0.4400000 \n",
      "Iter:    11 | Cost: 1.2466279 | Acc train: 0.4888889 | Acc validation: 0.4400000 \n",
      "Iter:    21 | Cost: 1.0075307 | Acc train: 0.5111111 | Acc validation: 0.5600000 \n",
      "Iter:    31 | Cost: 1.0313112 | Acc train: 0.5111111 | Acc validation: 0.5600000 \n",
      "Iter:    41 | Cost: 1.0046183 | Acc train: 0.4888889 | Acc validation: 0.4400000 \n",
      "Iter:    51 | Cost: 1.0076369 | Acc train: 0.4888889 | Acc validation: 0.4400000 \n",
      "Test accuracy: 0.5166666666666667\n",
      "Convergence for number of layers is equal to : 8\n",
      "----------------------------------------------------------------------\n",
      "Iter:     1 | Cost: 2.0581763 | Acc train: 0.4888889 | Acc validation: 0.4400000 \n",
      "Iter:    11 | Cost: 1.0321378 | Acc train: 0.4888889 | Acc validation: 0.4400000 \n",
      "Iter:    21 | Cost: 1.0713671 | Acc train: 0.5111111 | Acc validation: 0.5600000 \n",
      "Iter:    31 | Cost: 1.1293013 | Acc train: 0.5111111 | Acc validation: 0.5600000 \n",
      "Iter:    41 | Cost: 0.9994563 | Acc train: 0.5111111 | Acc validation: 0.5600000 \n",
      "Iter:    51 | Cost: 1.0308751 | Acc train: 0.4888889 | Acc validation: 0.4400000 \n",
      "Test accuracy: 0.5166666666666667\n",
      "Convergence for number of layers is equal to : 10\n",
      "----------------------------------------------------------------------\n",
      "Iter:     1 | Cost: 2.0269932 | Acc train: 0.4888889 | Acc validation: 0.4400000 \n",
      "Iter:    11 | Cost: 1.0145389 | Acc train: 0.4888889 | Acc validation: 0.4400000 \n",
      "Iter:    21 | Cost: 1.0771899 | Acc train: 0.5111111 | Acc validation: 0.5600000 \n",
      "Iter:    31 | Cost: 1.0286366 | Acc train: 0.4888889 | Acc validation: 0.4400000 \n",
      "Iter:    41 | Cost: 1.0216942 | Acc train: 0.4888889 | Acc validation: 0.4400000 \n",
      "Iter:    51 | Cost: 0.9978369 | Acc train: 0.5111111 | Acc validation: 0.5600000 \n",
      "Test accuracy: 0.48333333333333334\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "num_qubits = 4 # 4 qubits are needed for quantum circuit based on angle embedding\n",
    "num_layers = [1, 3, 6, 8, 10]\n",
    "accuracy_angle_embedding = []\n",
    "\n",
    "for i in range(len(num_layers)):\n",
    "    opt = optimize.NesterovMomentumOptimizer(0.01)\n",
    "    print(\"Convergence for number of layers is equal to : {}\".format(num_layers[i]))\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    # train the variational classifier\n",
    "    weights = 0.01 * np.random.randn(num_layers[i], num_qubits, 3, requires_grad=True)\n",
    "    bias = np.array(0.0, requires_grad=True)\n",
    "    for it in range(60):\n",
    "        # Update the weights by one optimizer step\n",
    "        batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "        feats_train_batch = feats_train[batch_index]\n",
    "        label_train_batch = label_train[batch_index]\n",
    "        weights, bias, _, _ = opt.step(cost_angle_embedding, weights, bias, feats_train_batch, label_train_batch)\n",
    "\n",
    "        # Compute predictions on train and validation set\n",
    "        predictions_train = [np.sign(variational_classifier_angle_embedding(weights, bias, f)) for f in feats_train]\n",
    "        predictions_val = [np.sign(variational_classifier_angle_embedding(weights, bias, f)) for f in feats_val]\n",
    "\n",
    "        # Compute accuracy on train and validation set\n",
    "        acc_train = accuracy(label_train, predictions_train)\n",
    "        acc_val = accuracy(label_val, predictions_val)\n",
    "        \n",
    "        if it%10 == 0:\n",
    "            print(\n",
    "                \"Iter: {:5d} | Cost: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f} \"\n",
    "                \"\".format(it + 1, cost_angle_embedding(weights, bias, train_X_norm, train_Y), acc_train, acc_val)\n",
    "            )\n",
    "    # check test accuracy\n",
    "    predictions_test = [np.sign(variational_classifier_angle_embedding(weights, bias, f)) for f in test_X_norm]\n",
    "    acc_test = accuracy(test_Y, predictions_test)\n",
    "    print(\"Test accuracy:\", acc_test)\n",
    "    accuracy_angle_embedding.append(acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfb4805",
   "metadata": {},
   "source": [
    "# Results and Analysis\n",
    "\n",
    "Based on the results with current hyperparameters used in the training, amplitude embedding performs much better than angle embedding. While the best accuracy achieved by amplitude embedding can reach 85.8% with 1 and 6 layers of ansatz, angle embedding can only reach 51.6% accuracy with 1, 6, and 8 layers of anstaz. In addition, the impact of the number of ansatz is not apparent according to the limited sample data presented in the current analysis. By its current state, as indicated in the results, 6 layers of ansatz turns to be the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c01cd7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "plt.plot(num_layers, accuracy_amplitude_embedding, \"b\", label=\"Amplitude Embedding\")\n",
    "plt.plot(num_layers, accuracy_angle_embedding, \"g\", label=\"Angle Embedding\")\n",
    "\n",
    "plt.ylabel(\"Accuracy on Test Data\")\n",
    "plt.xlabel(\"Number of Layers\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64db3008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
