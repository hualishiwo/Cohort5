{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518d9cb6",
   "metadata": {},
   "source": [
    "# Task 2 Encoding and Classifier\n",
    "\n",
    "\n",
    "Encoding the following files in a quantum circuit mock_train_set.csv and mock_test_set.csv in at least two different ways (these could be basis, angle,  amplitude, kernel or random encoding).\n",
    "Design a variational quantum circuit for each of the encodings, uses the column 4  as the target,  this is a binary class 0 and 1.\n",
    "You must  use the data  from column0 to column3 for your proposed classifier. \n",
    "Consider the ansatz you are going to design as a layer and find out how many layers are necessary to reach the best performance.\n",
    "\n",
    "Analyze and discuss the results.\n",
    "\n",
    "Feel free to use existing frameworks (e.g. PennyLane, Qiskit) for creating and training the circuits.\n",
    "This PennyLane demo can be useful: Training a quantum circuit with Pytorch, \n",
    "This Quantum Tensorflow tutorial can be useful: Training a quantum circuit with Tensorflow.\n",
    "\n",
    "For the variational circuit, you can try any circuit you want. You can start from one with a layer of RX, RZ and CNOTs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720c374b",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "26768f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import pennylane.optimize as optimize\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ad11f7",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "affbeaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the training dataset: (300, 4)\n",
      "The size of the test dataset: (120, 4)\n",
      "The size of the training label: (300,)\n",
      "The size of the test label: (120,)\n"
     ]
    }
   ],
   "source": [
    "def read_file(filename):\n",
    "    \"\"\"Read csv file\n",
    "    Args:\n",
    "      - filename (string): the file name\n",
    "    Returns:\n",
    "      - rows (list): a list of rows in the file\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        # creating a csv reader object\n",
    "        csvreader = csv.reader(csvfile)\n",
    "\n",
    "        # extracting each data row one by one\n",
    "        for row in csvreader:\n",
    "            rows.append(row)\n",
    "    return rows\n",
    "\n",
    "train_dataset = np.array(read_file(\"mock_train_set.csv\"), dtype=float)\n",
    "test_dataset = np.array(read_file(\"mock_test_set.csv\"), dtype=float)\n",
    "\n",
    "train_X, train_Y = train_dataset[1:, 0:4], train_dataset[1:, 4].astype('int')\n",
    "test_X, test_Y = test_dataset[1:, 0:4], test_dataset[1:, 4].astype('int')\n",
    "\n",
    "# shift label from {0, 1} to {-1, 1}\n",
    "train_Y = train_Y * 2 - np.ones(len(train_Y))\n",
    "test_Y = test_Y * 2 - np.ones(len(test_Y))\n",
    "\n",
    "print(\"The size of the training dataset:\", train_X.shape)\n",
    "print(\"The size of the test dataset:\", test_X.shape)\n",
    "print(\"The size of the training label:\", train_Y.shape)\n",
    "print(\"The size of the test label:\", test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7888a5ee",
   "metadata": {},
   "source": [
    "## Data Min-Max Normalization (Each Column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c2f05cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data for each column 1, 2, 3, 4\n",
    "def find_min_and_max(arr1, arr2):\n",
    "    \"\"\"Find max and min values for each column in datasets\n",
    "    Args:\n",
    "      - arr1, arr2: the datasets\n",
    "    Returns:\n",
    "      - arr_max, arr_min: arrays with max and min elements in each column, respectively\n",
    "    \"\"\"\n",
    "    arr1_max = np.max(arr1, axis=0)\n",
    "    arr2_max = np.max(arr2, axis=0)\n",
    "    arr_max = np.maximum(arr1_max, arr2_max)\n",
    "    \n",
    "    arr1_min = np.min(arr1, axis=0)\n",
    "    arr2_min = np.min(arr2, axis=0)\n",
    "    arr_min = np.minimum(arr1_min, arr2_min)\n",
    "    \n",
    "    return arr_max, arr_min   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5d3d45aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max for each column: [4.99561e+03 1.00000e+06 1.00000e+06 9.00000e+01]\n",
      "The min for each column: [31.71  1.    1.    1.  ]\n"
     ]
    }
   ],
   "source": [
    "X_max, X_min = find_min_and_max(train_X, test_X)\n",
    "print(\"The max for each column:\", X_max)\n",
    "print(\"The min for each column:\", X_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cd467e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max normalization \n",
    "for i in range(train_X.shape[1]):\n",
    "    train_X[:, i] = (train_X[:, i] - X_min[i]) / (X_max[i] - X_min[i])\n",
    "    test_X[:, i] = (test_X[:, i] - X_min[i]) / (X_max[i] - X_min[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3cb78140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First training X sample (min-max normalization):  [5.55520861e-01 9.99000999e-04 9.00000900e-06 2.13483146e-01]\n",
      "First test X sample (min-max normalization):  [0.59566873 0.00999901 0.00999901 0.83146067]\n"
     ]
    }
   ],
   "source": [
    "print(\"First training X sample (min-max normalization): \", train_X[0])\n",
    "print(\"First test X sample (min-max normalization): \", test_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad68a728",
   "metadata": {},
   "source": [
    "## Normalize to 1.0 (Each Row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e0dfbfb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First training X sample (normalized): [9.33444874e-01 1.67862708e-03 1.51227665e-05 3.58716949e-01]\n",
      "First test X sample (normalized): [0.58232672 0.00977505 0.00977505 0.81283731]\n"
     ]
    }
   ],
   "source": [
    "# normazlie each input\n",
    "normalization_train, normalization_test = np.sqrt(np.sum(train_X ** 2, -1)), np.sqrt(np.sum(test_X ** 2, -1))\n",
    "train_X_norm, test_X_norm = (train_X.T / normalization_train).T, (test_X.T / normalization_test).T\n",
    "print(\"First training X sample (normalized):\", train_X_norm[0])\n",
    "print(\"First test X sample (normalized):\", test_X_norm[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712e3906",
   "metadata": {},
   "source": [
    "# Quantum Classifier \n",
    "In this section, two state embedding methods are explored, they are amplitude embedding and angle embedding.\n",
    "## 1. Classifier based on Amplitude Embedding\n",
    "### Quantum Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "00831459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    \"\"\"Find square loss between labels and predictions\n",
    "    Args:\n",
    "      - labels: the sample labels\n",
    "      - predictions: the predicted labels\n",
    "    Returns:\n",
    "      - loss: square loss \n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "    \"\"\"Find prediction accuracy\n",
    "    Args:\n",
    "      - labels: the sample labels\n",
    "      - predictions: the predicted labels\n",
    "    Returns:\n",
    "      - accuracy: percentage of right prediction\n",
    "    \"\"\"\n",
    "    accuracy = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            accuracy = accuracy + 1\n",
    "    accuracy = accuracy / len(labels)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "85b53525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_amplitude_embedding(W):    \n",
    "    qml.Rot(W[0, 0], W[0, 1], W[0, 2], wires=0)\n",
    "    qml.Rot(W[1, 0], W[1, 1], W[1, 2], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "\n",
    "dev_amplitude_embedding = qml.device(\"default.qubit\", wires=2)\n",
    "@qml.qnode(dev_amplitude_embedding)\n",
    "def circuit_amplitude_embedding(weights, feature):\n",
    "    \"\"\"A quantum circuit used as classifier\n",
    "    Args:\n",
    "      - weights: parameters for layers in the circuit\n",
    "      - feature: sample data\n",
    "    Returns:\n",
    "      - expectation value: expectation value of Pauli z operator\n",
    "    \"\"\"\n",
    "    qml.AmplitudeEmbedding(feature, wires=[0, 1], normalize=True)\n",
    "\n",
    "    for W in weights:\n",
    "        layer_amplitude_embedding(W)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "def variational_classifier_amplitude_embedding(weights, bias, feature):\n",
    "    return circuit_amplitude_embedding(weights, feature) + bias\n",
    "\n",
    "def cost_amplitude_embedding(weights, bias, features, labels):\n",
    "    predictions = [variational_classifier_amplitude_embedding(weights, bias, f) for f in features]\n",
    "    return square_loss(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039664eb",
   "metadata": {},
   "source": [
    "## Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "66a7382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition training datasets to training and validation \n",
    "np.random.seed(0)\n",
    "num_data = len(train_Y)\n",
    "num_train = int(0.75 * num_data) # 75% dataset is used for training\n",
    "index = np.random.permutation(range(num_data))\n",
    "feats_train = train_X_norm[index[:num_train]]\n",
    "label_train = train_Y[index[:num_train]]\n",
    "feats_val = train_X_norm[index[num_train:]]\n",
    "label_val = train_Y[index[num_train:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "969ee50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence for number of layers is equal to : 1\n",
      "----------------------------------------------------------------------\n",
      "Iter:     1 | Cost: 1.2526602 | Acc train: 0.5555556 | Acc validation: 0.5600000 \n",
      "Iter:     6 | Cost: 1.2596546 | Acc train: 0.5600000 | Acc validation: 0.5600000 \n",
      "Iter:    11 | Cost: 1.2120025 | Acc train: 0.5644444 | Acc validation: 0.5733333 \n",
      "Iter:    16 | Cost: 1.2001280 | Acc train: 0.5733333 | Acc validation: 0.5733333 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15492/3072454167.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# Compute predictions on train and validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mpredictions_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariational_classifier_amplitude_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeats_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mpredictions_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariational_classifier_amplitude_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeats_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15492/3072454167.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# Compute predictions on train and validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mpredictions_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariational_classifier_amplitude_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeats_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mpredictions_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariational_classifier_amplitude_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeats_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15492/2724071224.py\u001b[0m in \u001b[0;36mvariational_classifier_amplitude_embedding\u001b[1;34m(weights, bias, feature)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mvariational_classifier_amplitude_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcircuit_amplitude_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcost_amplitude_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hackq\\lib\\site-packages\\pennylane\\qnode.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape_cached\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0musing_custom_cache\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhash\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         res = qml.execute(\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hackq\\lib\\site-packages\\pennylane\\interfaces\\batch\\__init__.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(tapes, device, gradient_fn, interface, mode, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform)\u001b[0m\n\u001b[0;32m    340\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgradient_fn\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"backprop\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minterface\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         return batch_fn(\n\u001b[1;32m--> 342\u001b[1;33m             \u001b[0mcache_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_execute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexpand_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m         )\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hackq\\lib\\site-packages\\pennylane\\interfaces\\batch\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(tapes, **kwargs)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[1;31m# execute all unique tapes that do not exist in the cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecution_tapes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mfinal_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hackq\\lib\\site-packages\\pennylane\\interfaces\\batch\\__init__.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(tapes, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=function-redefined\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[0mtapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mexpand_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtape\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtapes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0moriginal_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hackq\\lib\\contextlib.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hackq\\lib\\site-packages\\pennylane\\_qubit_device.py\u001b[0m in \u001b[0;36mbatch_execute\u001b[1;34m(self, circuits)\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m             \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hackq\\lib\\site-packages\\pennylane\\_qubit_device.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_sampled\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sampled\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmultiple_sampled_jobs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hackq\\lib\\site-packages\\pennylane\\_qubit_device.py\u001b[0m in \u001b[0;36mstatistics\u001b[1;34m(self, observables, shot_range, bin_size)\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[1;31m# Pass instances directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_type\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mExpectation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshot_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshot_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbin_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbin_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_type\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hackq\\lib\\site-packages\\pennylane\\devices\\default_qubit.py\u001b[0m in \u001b[0;36mexpval\u001b[1;34m(self, observable, shot_range, bin_size)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mqml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshot_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshot_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbin_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbin_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_unitary_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munitary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=no-self-use\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hackq\\lib\\site-packages\\pennylane\\_qubit_device.py\u001b[0m in \u001b[0;36mexpval\u001b[1;34m(self, observable, shot_range, bin_size)\u001b[0m\n\u001b[0;32m    780\u001b[0m                 ) from e\n\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 782\u001b[1;33m             \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwires\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobservable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwires\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    783\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meigvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hackq\\lib\\site-packages\\pennylane\\_qubit_device.py\u001b[0m in \u001b[0;36mprobability\u001b[1;34m(self, wires, shot_range, bin_size)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshots\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 690\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalytic_probability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwires\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwires\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimate_probability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwires\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwires\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshot_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshot_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbin_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbin_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hackq\\lib\\site-packages\\pennylane\\devices\\default_qubit.py\u001b[0m in \u001b[0;36manalytic_probability\u001b[1;34m(self, wires)\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m         \u001b[0mflat_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m         \u001b[0mreal_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[0mimag_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_imag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\hackq\\lib\\site-packages\\pennylane\\devices\\default_qubit_autograd.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(array)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0m_reduce_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[0m_reshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0m_flatten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     \u001b[0m_gather\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0m_einsum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = optimize.NesterovMomentumOptimizer(0.01)\n",
    "batch_size = 5\n",
    "num_qubits = 2 # 2 qubits are needed for quantum circuit based on amplitude embedding\n",
    "num_layers = [1, 3, 6, 12, 24]\n",
    "accuracy_amplitude_embedding = []\n",
    "\n",
    "for i in range(len(num_layers)):\n",
    "    print(\"Convergence for number of layers is equal to : {}\".format(num_layers[i]))\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    # train the variational classifier\n",
    "    weights_init = 0.01 * np.random.randn(num_layers[i], num_qubits, 3, requires_grad=True)\n",
    "    bias_init = np.array(0.0, requires_grad=True)\n",
    "    weights = weights_init\n",
    "    bias =  bias_init\n",
    "    for it in range(10):\n",
    "        # Update the weights by one optimizer step\n",
    "        batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "        feats_train_batch = feats_train[batch_index]\n",
    "        label_train_batch = label_train[batch_index]\n",
    "        weights, bias, _, _ = opt.step(cost_amplitude_embedding, weights, bias, feats_train_batch, label_train_batch)\n",
    "\n",
    "        # Compute predictions on train and validation set\n",
    "        predictions_train = [np.sign(variational_classifier_amplitude_embedding(weights, bias, f)) for f in feats_train]\n",
    "        predictions_val = [np.sign(variational_classifier_amplitude_embedding(weights, bias, f)) for f in feats_val]\n",
    "\n",
    "        # Compute accuracy on train and validation set\n",
    "        acc_train = accuracy(label_train, predictions_train)\n",
    "        acc_val = accuracy(label_val, predictions_val)\n",
    "        \n",
    "        if it%5 == 0:\n",
    "            print(\n",
    "                \"Iter: {:5d} | Cost: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f} \"\n",
    "                \"\".format(it + 1, cost_amplitude_embedding(weights, bias, features_train, train_Y), acc_train, acc_val)\n",
    "            )\n",
    "    # check test accuracy\n",
    "    predictions_test = [np.sign(variational_classifier_amplitude_embedding(weights, bias, f)) for f in features_test]\n",
    "    acc_test = accuracy(test_Y, predictions_test)\n",
    "    print(\"Test accuracy:\", acc_test)\n",
    "    accuracy_amplitude_embedding.append(acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f90620",
   "metadata": {},
   "source": [
    "## 2. Classifier based on Angle Embedding\n",
    "### Quantum Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76281d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_angle_embedding(W):\n",
    "    qml.Rot(W[0, 0], W[0, 1], W[0, 2], wires=0)\n",
    "    qml.Rot(W[1, 0], W[1, 1], W[1, 2], wires=1)\n",
    "    qml.Rot(W[2, 0], W[2, 1], W[2, 2], wires=2)\n",
    "    qml.Rot(W[3, 0], W[3, 1], W[3, 2], wires=3)\n",
    "\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "    qml.CNOT(wires=[2, 3])\n",
    "    qml.CNOT(wires=[3, 0]) \n",
    "    \n",
    "dev_angle_embedding = qml.device(\"default.qubit\", wires=4)\n",
    "@qml.qnode(dev_angle_embedding)\n",
    "def circuit_angle_embedding(weights, angles):\n",
    "     \"\"\"A quantum circuit used as classifier\n",
    "    Args:\n",
    "      - weights: parameters for layers in the circuit\n",
    "      - feature: sample data\n",
    "    Returns:\n",
    "      - expectation value: expectation value of Pauli z operator\n",
    "    \"\"\"\n",
    "    qml.AngleEmbedding(angles, wires=range(4), rotation='Z')\n",
    "\n",
    "    for W in weights:\n",
    "        layer_angle_embedding(W)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "def variational_classifier_angle_embedding(weights, bias, angles):\n",
    "    return circuit_angle_embedding(weights, angles) + bias\n",
    "\n",
    "def cost_angle_embedding(weights, bias, features, labels):\n",
    "    predictions = [variational_classifier_angle_embedding(weights, bias, f) for f in features]\n",
    "    return square_loss(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d45280",
   "metadata": {},
   "source": [
    "## Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c601829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition training datasets to training and validation \n",
    "np.random.seed(0)\n",
    "num_data = len(train_Y)\n",
    "num_train = int(0.75 * num_data) # 75% dataset is used for training\n",
    "index = np.random.permutation(range(num_data))\n",
    "feats_train = train_X_norm[index[:num_train]]\n",
    "label_train = train_Y[index[:num_train]]\n",
    "feats_val = train_X_norm[index[num_train:]]\n",
    "label_val = train_Y[index[num_train:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5861e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimize.NesterovMomentumOptimizer(0.01)\n",
    "batch_size = 5\n",
    "num_qubits = 4 # 4 qubits are needed for quantum circuit based on angle embedding\n",
    "num_layers = [1, 3, 6, 12, 24]\n",
    "accuracy_angle_embedding = []\n",
    "\n",
    "for i in range(len(num_layers)):\n",
    "    print(\"Convergence for number of layers is equal to : {}\".format(num_layers[i]))\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    # train the variational classifier\n",
    "    weights = 0.01 * np.random.randn(num_layers[i], num_qubits, 3, requires_grad=True)\n",
    "    bias = np.array(0.0, requires_grad=True)\n",
    "    for it in range(60):\n",
    "        # Update the weights by one optimizer step\n",
    "        batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "        feats_train_batch = feats_train[batch_index]\n",
    "        label_train_batch = label_train[batch_index]\n",
    "        weights, bias, _, _ = opt.step(cost_angle_embedding, weights, bias, feats_train_batch, label_train_batch)\n",
    "\n",
    "        # Compute predictions on train and validation set\n",
    "        predictions_train = [np.sign(variational_classifier_angle_embedding(weights, bias, f)) for f in feats_train]\n",
    "        predictions_val = [np.sign(variational_classifier_angle_embedding(weights, bias, f)) for f in feats_val]\n",
    "\n",
    "        # Compute accuracy on train and validation set\n",
    "        acc_train = accuracy(label_train, predictions_train)\n",
    "        acc_val = accuracy(label_val, predictions_val)\n",
    "        \n",
    "        if it%5 == 0:\n",
    "            print(\n",
    "                \"Iter: {:5d} | Cost: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f} \"\n",
    "                \"\".format(it + 1, cost_angle_embedding(weights, bias, features_train, train_Y), acc_train, acc_val)\n",
    "            )\n",
    "    # check test accuracy\n",
    "    predictions_test = [np.sign(variational_classifier_angle_embedding(weights, bias, f)) for f in features_test]\n",
    "    acc_test = accuracy(test_Y, predictions_test)\n",
    "    print(\"Test accuracy:\", acc_test)\n",
    "    accuracy_angle_embedding.append(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaac47f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
